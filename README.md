# Exploring Political Bias in LLMs Through Debate: A Multi-Agent Framework

This project investigates the performance of fine-tuned large language models (LLMs) with distinct left-leaning and right-leaning political biases in structured debates on politically sensitive topics. Leveraging models such as LLAMA 3.2 and PHI 1.5, we analyze their adherence to predefined biases, reasoning capabilities, and persuasiveness within a multi-agent framework and through automated evaluation metrics.

A comprehensive overview of the methodologies, results, and models used in this project, as well as the final paper, is available [here](https://isaac-berlin.github.io/LLM_Model_Bias/). This work was conducted as part of the final project for the course CSCI 5541: Natural Language Processing. We extend our gratitude to Professor Dongyeop Kang and the teaching assistants for their invaluable guidance and support throughout the project.
